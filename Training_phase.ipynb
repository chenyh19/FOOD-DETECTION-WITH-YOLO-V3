{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training_phase.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPO+w8w50drDUYh9ZlP56E5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cdNGVPjqinMo","colab_type":"text"},"source":["# **This notebooks aims to execute the full training process of our model from the data preprocessing to the training phase**"]},{"cell_type":"code","metadata":{"id":"kdnJDMh5qmeq","colab_type":"code","outputId":"f61fcf31-a963-4bce-d26e-5d55ebcfce25","executionInfo":{"status":"ok","timestamp":1581860187256,"user_tz":-60,"elapsed":1041,"user":{"displayName":"YANKAM NYA Emmanuelle Raissa","photoUrl":"","userId":"07208927259024299747"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IzG2qZFrNeOX","colab_type":"code","outputId":"c63a4029-0f0e-4a31-ded5-8af0f32059cf","executionInfo":{"status":"ok","timestamp":1581860133289,"user_tz":-60,"elapsed":11033,"user":{"displayName":"YANKAM NYA Emmanuelle Raissa","photoUrl":"","userId":"07208927259024299747"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#We need to downgrade this keras version to be able to use some functions\n","pip uninstall keras"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Uninstalling Keras-2.2.5:\n","  Would remove:\n","    /usr/local/lib/python3.6/dist-packages/Keras-2.2.5.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/docs/*\n","    /usr/local/lib/python3.6/dist-packages/keras/*\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.6/dist-packages/docs/md_autogen.py\n","    /usr/local/lib/python3.6/dist-packages/docs/update_docs.py\n","Proceed (y/n)? y\n","  Successfully uninstalled Keras-2.2.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cS17tOIINkDg","colab_type":"code","outputId":"b459739a-34d9-45ae-8b93-1f891063fdb3","executionInfo":{"status":"ok","timestamp":1581860152793,"user_tz":-60,"elapsed":6000,"user":{"displayName":"YANKAM NYA Emmanuelle Raissa","photoUrl":"","userId":"07208927259024299747"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["pip install keras==2.1.5"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting keras==2.1.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n","\r\u001b[K     |█                               | 10kB 27.4MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 6.4MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 7.5MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 143kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 153kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 163kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 184kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 194kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 204kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 215kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 225kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 235kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 245kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 256kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 266kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 276kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 286kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 296kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 307kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 317kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 327kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 337kB 9.2MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.17.5)\n","Installing collected packages: keras\n","Successfully installed keras-2.1.5\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["keras"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"90qnb9XM069D","colab_type":"code","outputId":"7caf2f6f-b202-4c8d-8267-bf59862fc506","executionInfo":{"status":"ok","timestamp":1581860170256,"user_tz":-60,"elapsed":2018,"user":{"displayName":"YANKAM NYA Emmanuelle Raissa","photoUrl":"","userId":"07208927259024299747"}},"colab":{"base_uri":"https://localhost:8080/","height":97}},"source":["import keras\n","print(keras.__version__)\n","#We check the keras version to make sure that the downgrading operation went well."],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2.1.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_RIRuB7FrKNm","colab_type":"code","colab":{}},"source":["\"\"\"\n","Train the YOLO model for the Detection and classification of “salad & fruit bar” tasks.\n","\n","\"\"\"\n","\n","#Librairies importation\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Technical test - Trayvisor')\n","import numpy as np\n","from datetime import datetime\n","from random import shuffle\n","import keras.backend as K\n","from keras.layers import Input, Lambda\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from yolo3.model import preprocess_true_boxes, yolo_body, yolo_loss\n","from yolo3.utils import get_random_data\n","\n","\n","def BB_extraction(data,image_path):\n","    '''Extracts image name,label and Bounding Box coordinates\n","\n","    Parameters\n","    ----------\n","    -data: .npy file containing the data that'll be used to train the CNN.\n","    -image_path: str, is the path where we find the images\n","\n","    Returns\n","    -------\n","    -Data_info: list, shape like [[image1 absolute path,box11,..box1m],...[image n absolute path, boxn1,..boxn] ]\n","     where box=[xmin,ymin,xmax,ymax,class_index], contains the main information about our dataset.\n","    -classes: list, contains the name of the various classes found in our dataset'''\n","\n","    classes=[]\n","    Data_info=[]\n","    bv=0\n","    sv=0\n","    for number in range(len(data)):\n","        liste=[]\n","        liste.append(image_path+'/'+data[number]['name'])\n","                      \n","        for i in range(len(data[number]['boxes'])):\n","            cord=data[number]['boxes'][i]['box']   \n","            cord[2]+=cord[0]\n","            cord[3]+=cord[1]\n","            class_name=data[number]['boxes'][i]['id']\n","                      \n","            if(class_name not in classes):\n","                classes.append(class_name)\n","                \n","            if(class_name=='big_vrac'):\n","                bv+=1\n","            else:\n","                sv+=1\n","                \n","            cord.append(classes.index(class_name))\n","            \n","            liste.append(cord)\n","            \n","        Data_info.append(liste)\n","    print('Big vrac and small vrac occurences respectively:',bv,sv)\n","    \n","    del data\n","            \n","    return Data_info,classes\n","\n","def test_train_split(data,data_path,test_ratio=0.2):\n","\n","    '''Splits the dataset into train set and test set and save the train and test sets in a directory.\n","\n","    Parameters\n","    ----------\n","    -data: list, shape like [[image1 absolute path,box11,..box1m],...[image n absolute path, boxn1,..boxn] ]\n","     where box=[xmin,ymin,xmax,ymax,class_index], contains the main information about our dataset.\n","    -data_path: str, is the path where we want to save our train and test sets.\n","    test_ratio: float, between 0 and 1, is the percentage (of the whole dataset) that will be used to create the test set.\n","\n","    Returns\n","    -------\n","    -train_set: list, corresponds to the training set.\n","    -test_set: list, corresponds to the test set.'''\n","\n","    train_set=[]\n","    test_set=[]\n","    shuffle(data)\n","    num=int(len(data)-len(data)*test_ratio)\n","    train_set=data[:num]\n","    test_set=data[num:]\n","        \n","    file_path=new_file_name(data_path)\n","    os.mkdir(file_path)\n","    np.save(file_path+'/test.npy',np.array(test_set))\n","    np.save(file_path+'/train.npy',np.array(test_set))\n","        \n","    return train_set, test_set\n","\n","def new_file_name(path):\n","  '''Creates a folder name based on the current date and hour.\n","\n","    Parameters\n","    ----------\n","    -path: str, is the path where a new folder will be created\n","    Returns\n","    -------\n","    -file_path: str, corresponds to the name of a new folder'''\n","    \n","  date=datetime.now()\n","  file_path=path+'/dataset'+str(date.year)+str(date.month)+str(date.day)+str(date.hour)+str(date.minute)+str(date.second)\n","  return file_path\n","\n","def get_anchors(anchors_liste):\n","    '''Creates anchors that will be used for the detection task'''\n","    return np.array(anchors_liste, dtype='float').reshape(-1, 2)   \n","\n","def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2, weights_path='./yolo_weights.h5'):\n","    '''Creates a CNN model (YOLO model).\n","\n","    Parameters\n","    ----------\n","    -input_shape: tuple, represents the shape of the image that will be used as the input of our model.\n","    -anchors: array, contains the anchors that will be used for the detection task.\n","    -num_classes: int, is the number of classes without the background.\n","    -load_pretrained: Bool, says if we want to use the weights of a previous trained model as a starting point or not.\n","    -freeze_body: int, specifes the number of layers we want to freeze during the training phase.\n","    -weights_path: str, is the path where we find the pretrained weights.\n","    Returns\n","    -------\n","    -A CNN model'''\n","  \n","    K.clear_session() # get a new session\n","    image_input = Input(shape=(None, None, 3))\n","    h, w = input_shape\n","    num_anchors = len(anchors)\n","\n","    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n","        num_anchors//3, num_classes+5)) for l in range(3)]\n","\n","    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n","    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n","\n","    if load_pretrained:\n","        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n","        print('Load weights {}.'.format(weights_path))\n","        if freeze_body in [1, 2]:\n","            # Freeze darknet53 body or freeze all but 3 output layers.\n","            num = (185, len(model_body.layers)-3)[freeze_body-1]\n","            for i in range(num): model_body.layers[i].trainable = False\n","            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n","\n","    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n","        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n","        [*model_body.output, *y_true])\n","    model = Model([model_body.input, *y_true], model_loss)\n","\n","    return model\n","\n","def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n","    '''Generates the data that will be fed into the CNN'''\n","    n = len(annotation_lines)\n","    i = 0\n","    while True:\n","        image_data = []\n","        box_data = []\n","        for b in range(batch_size):\n","            if i==0:\n","                np.random.shuffle(annotation_lines)\n","            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n","            image_data.append(image)\n","            box_data.append(box)\n","            i = (i+1) % n\n","        image_data = np.array(image_data)\n","        box_data = np.array(box_data)\n","        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n","        yield [image_data, *y_true], np.zeros(batch_size)\n","\n","def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n","  '''Generates the data that will be fed into the CNN'''\n","  n = len(annotation_lines)\n","  if n==0 or batch_size<=0: return None\n","  return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPqw_GdbsdZH","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","\n","  #We define a directory \n","    log_dir = '/content/drive/My Drive/Colab Notebooks/Technical test - Trayvisor/model_weights'\n","    \n","    #We define the Anchor size\n","    ANCHOR_SIZE=[10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326]\n","    \n","    #data_path is the path where we find the trayvisor_test_db.npy which contains the data\n","    data_path='/content/drive/My Drive/Colab Notebooks/Technical test - Trayvisor/trayvisor_test_db.npy'\n","    \n","    #path is the path where we find the images\n","    path='/content/drive/My Drive/Colab Notebooks/Technical test - Trayvisor/images'\n","\n","    #we define a path where we'll save the test set and train set\n","    save_dataset_path='/content/drive/My Drive/Colab Notebooks/Technical test - Trayvisor'\n","    \n","    #we get the data from the .npy file \n","    label=np.load(data_path,allow_pickle=True)\n","    \n","    #We extract the BB coordinates and the classes\n","    data_info,class_names=BB_extraction(label,path)\n","     \n","    num_classes = len(class_names)\n","    \n","    anchors = get_anchors(ANCHOR_SIZE)\n","    #We split our dataset into test and train sets\n","    train,test=test_train_split(data_info,save_dataset_path)\n","\n","    input_shape = (416,416) # multiple of 32, hw\n","    \n","    #We then create the model as well as the checkpoints \n","    model = create_model(input_shape, anchors, num_classes, freeze_body=2, weights_path='/content/drive/My Drive/Colab Notebooks/Technical test - Trayvisor/yolo_weights.h5')\n","    logging = TensorBoard(log_dir=log_dir)\n","    checkpoint = ModelCheckpoint(log_dir + '/ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n","        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n","    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n","\n","    # Train with frozen layers first, to get a stable loss.\n","    if True:\n","        model.compile(optimizer=Adam(lr=1e-3), loss={\n","            # use custom yolo_loss Lambda layer.\n","            'yolo_loss': lambda y_true, y_pred: y_pred})\n","\n","        batch_size = 32\n","        print('Train on {} samples, val on {} samples, with batch size {}.'.format(len(train), len(test), batch_size))\n","        model.fit_generator(data_generator_wrapper(train, batch_size, input_shape, anchors, num_classes),\n","                steps_per_epoch=max(1, len(train)//batch_size),\n","                validation_data=data_generator_wrapper(test, batch_size, input_shape, anchors, num_classes),\n","                validation_steps=max(1, len(test)//batch_size),\n","                epochs=50,\n","                initial_epoch=0,\n","                callbacks=[logging, checkpoint])\n","        model.save_weights(log_dir + '/trained_weights_stage_1.h5')\n","\n","    # Unfreeze and continue training, to fine-tune.\n","    if True:\n","        for i in range(len(model.layers)):\n","            model.layers[i].trainable = True\n","        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n","        print('Unfreeze all of the layers.')\n","\n","        batch_size = 8 \n","        print('Train on {} samples, val on {} samples, with batch size {}.'.format(len(train), len(test), batch_size))\n","        model.fit_generator(data_generator_wrapper(train, batch_size, input_shape, anchors, num_classes),\n","            steps_per_epoch=max(1, len(train)//batch_size),\n","            validation_data=data_generator_wrapper(test, batch_size, input_shape, anchors, num_classes),\n","            validation_steps=max(1, len(test)//batch_size),\n","            epochs=100,\n","            initial_epoch=50,\n","            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n","        model.save_weights(log_dir + '/trained_weights_final.h5') "],"execution_count":0,"outputs":[]}]}